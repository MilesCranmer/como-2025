{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd470f8",
   "metadata": {},
   "source": [
    "# Tutorial 1 - Building a Monte Carlo generator\n",
    "\n",
    "- Welcome! \n",
    "- Questions, anything unclear? Please ask any of us anytime!\n",
    "- Plan for today:\n",
    "  - write a very simple and short Monte Carlo program and produce LO predictions\n",
    "  - calculate structure functions and compare with data; improve the theory predictions and see the impact\n",
    "  - Less focus on *why* and more focus on *how*\n",
    "- For the exercises: if you'd like team up, please do! If you want to solve everything yourself that's also fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdbd526-3b99-45a9-a23e-8add5c407253",
   "metadata": {},
   "source": [
    "## Technical information\n",
    "\n",
    "1. Open a terminal and `cd` to your `como-2025` directory and `git pull` to update it\n",
    "2. Activate the `env_como` environment to run this notebook:\n",
    "   ```\n",
    "   conda activate env_como\n",
    "   jupyter lab w1t1-nlo-crash-course/introduction.ipynb\n",
    "   ```\n",
    "   you should now see this notebook!\n",
    "3. we finally need a PDF set with a non-zero photon PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394eb657-17df-40c1-badf-9c35d657bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF already installed: NNPDF31_nnlo_as_0118_luxqed (use --upgrade to force install)\n"
     ]
    }
   ],
   "source": [
    "!lhapdf install NNPDF31_nnlo_as_0118_luxqed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ee109",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Motivation: what do we need theory predictions for?\n",
    "\n",
    "- With the standard model of particle physics, we're often interested in these two tasks:\n",
    "  1. Extract quantities we can't calculate: If we trust data and theory, we often want to extract quantities that are hard/impossible to calculate! For instance, parton distribution functions (PDFs), see picture below.\n",
    "  2. Answer: how good is the standard model? To answer this question, we must compare theory predictions with experimental measurements, using (universal!) PDFs as input\n",
    "  \n",
    "![fitting PDFs](figures/Fit.png)\n",
    "\n",
    "- theory predictions important (not the only) ingredient to answer these types of questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf86aeb-1832-4257-b784-1c17a7109b8c",
   "metadata": {},
   "source": [
    "# How do we calculate a prediction?\n",
    "\n",
    "- there's a 'recipe' that we will present\n",
    "- important ingredients in the following:\n",
    "  1. factorization (covered in Melissa's lectures) and\n",
    "  2. perturbation theory (you should know this from quantum mechanics)\n",
    "  3. interpolation grids (technical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13429121-0bd7-48f1-a4b6-70a45e05c42d",
   "metadata": {},
   "source": [
    "## 1. Factorization\n",
    "\n",
    "- Many colliders use bound states: protons (LHC), anti-protons (Tevatron), or heavier nuclei like lead (LHC)\n",
    "- Bound states are very difficult objects, but if we\n",
    "  - either scatter them off each other with high enough energies\n",
    "  - or if we probe them using leptons\n",
    "  we usually assume that short-distance dynamics (scattering process) *factorizes* from long-distance dynamics (interaction in the hadron)\n",
    "- Essentially we're assuming that in the very short moment when the scattering happens we don't scatter the bound states but rather one constituent of each bound states which we call *partons* and we neglect the rest\n",
    "- Partons are elementary particles (quarks $\\mathrm{q}$, gluons $\\mathrm{g}$, but also photons $\\gamma$, leptons $\\ell$ and so on), and we can easily calculate with them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11108a56-75c2-4ed1-b66b-c8c106810dae",
   "metadata": {},
   "source": [
    "### Parton distribution functions (PDFs)\n",
    "\n",
    "- Rough idea: The translation between *partonic* cross sections and *hadronic* cross sections is provided by PDFs $f_a^h (x)$, which describe the 'probability' of finding a parton $a$ in hadron $h$ with momentum fraction $x \\in [0, 1]$ during a collision\n",
    "- for one hadron (for instance HERA):\n",
    "  $$ \\left\\langle \\frac{\\sigma^{h \\ell \\to F}}{\\mathrm{d} \\mathcal{O}} \\right\\rangle = \\sum_{a} \\int_0^1 \\mathrm{d} z f_a^h (z) \\frac{\\sigma_{ab \\to F} (z)}{\\mathrm{d} \\mathcal{O}} $$\n",
    "- for two hadrons (for instance LHC):\n",
    "  $$ \\left\\langle \\frac{\\sigma^{hh \\to F}}{\\mathrm{d} \\mathcal{O}} \\right\\rangle = \\sum_{a,b} \\int \\mathrm{d} x_1 \\mathrm{d} x_2 f_a^h (x_1) f_b^h (x_2) \\frac{\\sigma_{ab \\to F} (x_1, x_2)}{\\mathrm{d} \\mathcal{O}} $$\n",
    "- these are our 'master formulae':\n",
    "  1. We can calculate the hadronic cross sections $\\sigma_{ab \\to F} (x_1, x_2)/\\mathrm{d} \\mathcal{O}$ using the previously determined PDFs\n",
    "  2. or we use predictions and the corresponding measurements to fit PDFs\n",
    "- LHAPDF, which you should have installed, is the software to access the numerical values of PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd363dd-7207-4bcf-93f1-201e8b75d3d7",
   "metadata": {},
   "source": [
    "## 2. Perturbation theory: calculating a partonic cross section\n",
    "\n",
    "- Standard model Lagrangian $\\mathcal{L}_\\text{SM}$, solve the equations of motion, just like in classical mechanics\n",
    "- Well, not quite: EOMs are coupled, non-linear differential equations\n",
    "- A good tool is perturbation theory: divide Lagrangian into free fields + small perturbation\n",
    "- In the SM the perturbation is measured in the couplings $\\alpha_s (M_\\mathrm{Z}^2) = 0.118$ and $\\alpha(0) \\approx 1/137 \\approx 0.0073$\n",
    "- expand in those two couplings:\n",
    "  $$ \\frac{\\sigma_{ab} (x_1, x_2)}{\\mathrm{d} \\mathcal{O}} = \\sum_{n,m} \\alpha_\\mathrm{s}^n \\alpha^m \\frac{\\sigma_{ab}^{n,m} (x_1, x_2)}{\\mathrm{d} \\mathcal{O}} $$\n",
    "- since $\\alpha_s \\gg \\alpha$ we usually look only at the lowest order $m$ and calculate corrections in $n$: QCD corrections\n",
    "- this isn't always reliable, sometimes electroweak (EW) corrections are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917337e8-a406-4517-9af3-33c6e72f37a8",
   "metadata": {},
   "source": [
    "## 3. Interpolation grids: predictions independent of their PDFs and strong coupling\n",
    "\n",
    "Inserting the perturbative expansion into the master formula:\n",
    "\n",
    "$$ \\left\\langle \\frac{\\sigma^{hh \\to F}}{\\mathrm{d} \\mathcal{O}} \\right\\rangle = \\sum_{a,b} \\sum_{n,m} \\int \\mathrm{d} x_1 \\mathrm{d} x_2 f_a^h (x_1) f_b^h (x_2) \\alpha_\\mathrm{s}^n \\alpha^m \\frac{\\sigma_{ab \\to F}^{n,m} (x_1, x_2)}{\\mathrm{d} \\mathcal{O}} $$\n",
    "\n",
    "We can construct $\\sigma_{ab \\to F}^{n,m} (x_1, x_2) / \\mathrm{d} \\mathcal{O}$ and call that 'interpolation grid'. They have the advantage that one can very quickly (less than a second) perform the integrals above with any PDF set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d1864-a5c6-44e0-b226-b615814cb29f",
   "metadata": {},
   "source": [
    "# Leading-order (LO) calculations recipe\n",
    "\n",
    "In the following we will calculate\n",
    "\n",
    "- the cross section of the production of a same-flavour opposite-sign (SFOS) lepton-pair (also known as Drell-Yan lepton-pair production), for instance muons\n",
    "- at the LHC: $\\mathrm{p}\\mathrm{p} \\to \\ell\\bar{\\ell}$ @ 7 TeV,\n",
    "- differentially in the rapidity of the lepton pair,\n",
    "- in the setup given by <https://arxiv.org/abs/1310.7291>.\n",
    "\n",
    "We'll write a Monte Carlo integrator that calculates a part of this process and produces an interpolation grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9dcaa-0982-485f-957b-ed37db9a78c1",
   "metadata": {},
   "source": [
    "## 1. Write down observable definition and master formula\n",
    "\n",
    "We use the master formula for two incoming protons:\n",
    "\n",
    "$$ \\sigma^{\\mathrm{p}\\mathrm{p} \\to \\ell\\bar{\\ell}} = \\sum_{a,b} \\int \\mathrm{d} x_1 \\mathrm{d} x_2 f_a^\\mathrm{p} (x_1) f_b^\\mathrm{p} (x_2) \\sigma_{ab \\to \\ell\\bar{\\ell}} (x_1, x_2) $$\n",
    "\n",
    "For simplicity we restrict ourselves to the photon-photon contribution, so $a, b = \\gamma$ and use a PDF with a non-zero photon: `NNPDF31_nnlo_as_0118_luxqed`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64186087-86d9-42e5-9dd2-28578ac2f60a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Draw all Feynman diagrams\n",
    "\n",
    "You need to identify all relevant input states and all valid output states, connect them in all possible ways using the allowed vertices and propagators and assign four-momenta to them.\n",
    "\n",
    "In our example of photon-photon scattering to SFOS lepton-pair there are two diagrams: one with a $t$-channel propagator and one with a $u$ propagator:\n",
    "\n",
    "<img src=\"figures/lo-t.png\" width=260 height=260 />  <img src=\"figures/lo-u.png\" width=260 height=260 />\n",
    "\n",
    "Simple exercise: Write down the expressions for the matrix element for these diagrams. You can treat the particles as being massless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8e0b0-d664-4f49-9bf3-a167c82dd5a1",
   "metadata": {},
   "source": [
    "## 3. Compute matrix elements\n",
    "\n",
    "Sum all amplitudes and take the modulus squared. It is common practice to also account for the flux factor and the spin and color sums together with their eventual average. Recall to average on the input and to sum on the output. \n",
    "\n",
    "Exercise to do at home: compute the total squared matrix element in terms of Mandelstam variables (you should end up with the expression below).\n",
    "\n",
    "In our example we find:\n",
    "$$ \\frac {1}{2 s} |\\mathcal M_t + \\mathcal M_u |^2 =  \\frac{\\alpha_s^2}{2s}\\left( \\frac{t}{u} + \\frac{u}{t} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc0bf80-787e-427c-aec4-f835309eaf76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T13:54:13.409092Z",
     "start_time": "2025-07-10T13:54:13.406882Z"
    }
   },
   "outputs": [],
   "source": [
    "def photon_photon_matrix_element(s: float, t: float, u: float) -> float:\n",
    "    alpha0 = 1.0 / 137.03599911\n",
    "    return # INSERT HERE THE SQUARED MATRIX ELEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f5606-83ca-45e0-bc1a-87600b0cc1de",
   "metadata": {},
   "source": [
    "## 4. Determine phase space decomposition\n",
    "\n",
    "Given the initial states with momenta $k_1$ and $k_2$ we need to integrate the squared matrix elements over all possible momenta, that is all momenta which fulfill momentum conservation and which are on-shell: $ p_i^2 = m_i^2 $. In general this integral (Lorentz invariant phase-space (LIPS)) is:\n",
    "\n",
    "$$ \\int \\mathrm{d} \\mathrm{LIPS} = \\int \\left( \\prod_{i=1}^n \\mathrm{d}^4 p_i \\right) \\, \\delta^{(4)} \\left( k_1 + k_2 - \\sum_{i=1}^n p_i \\right) \\prod_{i = 1}^n \\delta \\left( p_i^2 - m_i^2 \\right) $$\n",
    "\n",
    "and has $4n$ integration dimensions, reduced to $3n - 4$ through the momentum conservation ($-4$) and on-shell conditions ($-n$).\n",
    "\n",
    "In our example we have two massless final state particles ($n = 2$ and $m_1 = m_2 = 0$), so effectively we integrate over $3n - 4 = 2$ dimensions. We choose to integrate over these two variables:\n",
    "1. $\\cos \\theta$, where $\\theta$ measures the angle of one of the leptons w.r.t. the beam axis and\n",
    "2. the angle $\\phi$, which is another angle transverse to the beam axis.\n",
    "\n",
    "Matrix elements do not depend on the angle $\\phi$, since the collision is symmetric around the beam axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f85c0-be69-4007-9871-9ce4797f4fe3",
   "metadata": {},
   "source": [
    "## 5. Compute phase space integrals\n",
    "\n",
    "Our master formula,\n",
    "\n",
    "$$ \\sigma^{\\mathrm{p}\\mathrm{p} \\to \\ell\\bar{\\ell}} = \\sum_{a,b} \\int \\mathrm{d} x_1 \\mathrm{d} x_2 f_a^\\mathrm{p} (x_1) f_b^\\mathrm{p} (x_2) \\sigma_{ab \\to \\ell\\bar{\\ell}} (x_1, x_2) $$\n",
    "\n",
    "requires us to integrate over all possible momentum fractions $x_1$ and $x_2$ of the two PDFs. We do this by rewriting the integral into $\\tau = x_1x_2 = \\hat{s}/s$, the relative centre-of-mass energy squared (the hat refers to partonic quantities) and another independent variable $y = x_1$ (which despite it's name isn't the rapidity):\n",
    "\n",
    "$$ \\int_0^1 \\mathrm{d} x_1 \\int_0^1 \\mathrm{d} x_2 \\to \\int_{\\tau_0}^1 \\mathrm{d} \\tau \\int_0^1 \\mathrm{d} y$$\n",
    "\n",
    "The exact form of this transformation isn't really important, but it is chosen such that the jacobian contains the inverse flux factor, cancelling the flux factor multiplied to the squared matrix elements above.\n",
    "\n",
    "We approximate the integrals numerically by using a Monte Carlo integration, which computes the average of the integrand evaluated using uniformly chosen random numbers $r_1, r_2, r_3$:\n",
    "\n",
    "$$ \\int_0^1 \\mathrm{d} r_1 \\int_0^1 \\mathrm{d} r_2 \\int_0^1 \\mathrm{d} r_3 g(r_1, r_2, r_3) \\approx \\frac{1}{N} \\sum_{i=1}^N g(r_1^i, r_2^i, r_3^i) $$\n",
    "\n",
    "Translated to Python code this reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357d81ff-5c6b-4514-82f7-e5575b80215a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T13:37:44.489807Z",
     "start_time": "2025-07-10T13:37:44.486434Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def hadronic_ps_gen(\n",
    "    mmin: float, mmax: float\n",
    ") -> Tuple[float, float, float, float, float, float]:\n",
    "    r\"\"\"Hadronic phase space generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mmin :\n",
    "        minimal partonic centre-of-mass energy :math:`\\sqrt{s_{min}}`\n",
    "    mmax :\n",
    "        maximal partonic centre-of-mass energy :math:`\\sqrt{s_{max}}`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    s :\n",
    "        Mandelstam s\n",
    "    t :\n",
    "        Mandelstam t\n",
    "    u :\n",
    "        Mandelstam u\n",
    "    x1 :\n",
    "        first momentum fraction\n",
    "    x2 :\n",
    "        second momentum fraction\n",
    "    jacobian :\n",
    "        jacobian from the uniform generation\n",
    "\n",
    "    \"\"\"\n",
    "    smin = mmin * mmin\n",
    "    smax = mmax * mmax\n",
    "\n",
    "    r1 = np.random.uniform()\n",
    "    r2 = np.random.uniform()\n",
    "    r3 = np.random.uniform()\n",
    "    \n",
    "    # generate partonic x1 and x2\n",
    "    tau0 = smin / smax\n",
    "    tau = pow(tau0, r1)\n",
    "    y = pow(tau, 1.0 - r2)\n",
    "    x1 = y\n",
    "    x2 = tau / y\n",
    "    s = tau * smax\n",
    "\n",
    "    jacobian = tau * np.log(tau0) * np.log(tau0) * r1\n",
    "\n",
    "    # theta integration (in the CMS)\n",
    "    cos_theta = 2.0 * r3 - 1.0\n",
    "    jacobian *= 2.0\n",
    "\n",
    "    # reconstruct invariants (in the CMS)\n",
    "    t = -0.5 * s * (1.0 - cos_theta)\n",
    "    u = -0.5 * s * (1.0 + cos_theta)\n",
    "\n",
    "    # phi integration\n",
    "    jacobian *= 2.0 * math.pi\n",
    "\n",
    "    return [s, t, u, x1, x2, jacobian]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f003f3",
   "metadata": {},
   "source": [
    "Now we can test the integration by generating a phase-space point between $s_\\text{min} = (10~\\text{GeV})^2$ and $s_\\text{max} = (7000~\\text{GeV})^2$ (our hadronic centre-of-mass energy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f1be2c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T13:38:05.042306Z",
     "start_time": "2025-07-10T13:38:05.040043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = 71814.09850068686\n",
      "t = -17618.322640990315\n",
      "u = -54195.77585969654\n",
      "\n",
      "x1 = 0.06309745515052462\n",
      "x2 = 0.02322746366642661\n",
      "\n",
      "s + t + u = 0.0\n"
     ]
    }
   ],
   "source": [
    "[s, t, u, x1, x2, jacobian] = hadronic_ps_gen(10.0, 7000.0)\n",
    "\n",
    "print(\"s = {}\\nt = {}\\nu = {}\\n\\nx1 = {}\\nx2 = {}\\n\\ns + t + u = {}\".format(s, t, u, x1, x2, s + t + u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a135784-1ce2-49f2-8c21-b1447c8eb83a",
   "metadata": {},
   "source": [
    "## 6. Join phase space integration and matrix elements\n",
    "\n",
    "Finally, we have to\n",
    "- put the integral together with the squared matrix elements,\n",
    "- transform the phase-space variables into the well-known LAB quantities, and\n",
    "- we want to simulate the setup from CMS DY 7 TeV, see: <https://arxiv.org/abs/1310.7291>\n",
    "\n",
    "This means, we\n",
    "- add phase-space cuts:\n",
    "  - $ p_\\mathrm{T}^\\ell > 14~\\text{GeV} $\n",
    "  - $ |y^\\ell| < 2.4 $\n",
    "  - $ 60~\\text{GeV} < M_{\\ell\\bar{\\ell}} < 120~\\text{GeV} $\n",
    "- and we want the differential cross section w.r.t. $|y_{\\ell\\bar{\\ell}}|$ (which is the rapidity in this case) with bin limits $0 < |y_{\\ell\\bar{\\ell}}| < 2.4$, in steps of $0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb89769-55ad-43b8-8844-41538ae2e9a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T13:51:03.774566Z",
     "start_time": "2025-07-10T13:51:03.668874Z"
    }
   },
   "outputs": [],
   "source": [
    "import pineappl\n",
    "\n",
    "def fill_grid(grid: pineappl.grid.Grid, calls: int):\n",
    "    \"\"\"Fill grid with points.\"\"\"\n",
    "\n",
    "    # in GeV^2 pbarn\n",
    "    hbarc2 = 389379372.1\n",
    "\n",
    "    # perform Monte Carlo sum\n",
    "    for _ in range(calls):\n",
    "        # compute phase space\n",
    "        s, t, u, x1, x2, jacobian = hadronic_ps_gen(10.0, 7000.0)\n",
    "\n",
    "        # build observables\n",
    "        ptl = np.sqrt((t * u / s))\n",
    "        mll = np.sqrt(s)\n",
    "        yll = 0.5 * np.log(x1 / x2)\n",
    "        ylp = np.abs(yll + math.acosh(0.5 * mll / ptl))\n",
    "        ylm = np.abs(yll - math.acosh(0.5 * mll / ptl))\n",
    "\n",
    "        # apply conversion factor\n",
    "        jacobian *= hbarc2 / calls\n",
    "\n",
    "        # cuts for LO for the invariant-mass slice containing the Z-peak from CMS (7 TeV): https://arxiv.org/abs/1310.7291\n",
    "        if (\n",
    "            \n",
    "            # INSERT HERE THE PHASE SPACE CUTS\n",
    "        ):\n",
    "            # continuing means this we don't call fill below that means this event counts as zero or it 'cut away'\n",
    "            continue\n",
    "\n",
    "        # build event\n",
    "        weight = jacobian * photon_photon_matrix_element(s, u, t)\n",
    "        # set factorization and renormalization scale to (roughly) the Z-boson mass\n",
    "        q2 = 90.0 * 90.0\n",
    "    \n",
    "        # fill the interpolation grid\n",
    "        grid.fill(x1, x2, q2, 0, np.abs(yll), 0, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fcfc8-2fd9-45e2-9bff-df12e0759392",
   "metadata": {},
   "source": [
    "We want our results stored in an interpolation grid, which is independent of PDFs and the strong coupling. To create a `Grid`, we need to give it a few bits of information. We have to tell it that\n",
    "\n",
    "- our initial state is photon-photon, or in PDG Monte Carlo IDs `(22, 22)`\n",
    "- the perturbative order in $\\alpha^2$\n",
    "- as per CMS's setup we bin the observable from $0$ to $2.4$ in steps of $0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26191d31-ea97-4b57-880c-2a20713cff6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T13:51:06.647834Z",
     "start_time": "2025-07-10T13:51:06.645200Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_grid(calls: int) -> pineappl.grid.Grid:\n",
    "    \"\"\"Generate the grid.\"\"\"\n",
    "    # create a new luminosity function for the $\\gamma\\gamma$ initial state\n",
    "    lumi_entries = [pineappl.lumi.LumiEntry([(22, 22, 1.0)])]\n",
    "    # only LO $\\alpha_\\mathrm{s}^0 \\alpha^2 \\log^0(\\xi_\\mathrm{R}) \\log^0(\\xi_\\mathrm{F})$\n",
    "    orders = [pineappl.grid.Order(0, 2, 0, 0)]\n",
    "    bins = np.arange(0, 2.4, 0.1)\n",
    "    params = pineappl.subgrid.SubgridParams()\n",
    "    grid = pineappl.grid.Grid.create(lumi_entries, orders, bins, params)\n",
    "\n",
    "    # fill the grid with phase-space points\n",
    "    print(f\"Generating {calls} events, please wait...\")\n",
    "    fill_grid(grid, calls)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823abe6",
   "metadata": {},
   "source": [
    "You can play a bit with the Monte Carlo statistics, to produce smooth results. To generate the full theory prediction, we must also use our master formula and convolute the interpolation grid with the two photon PDFs. Finally, let's plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "id": "94775264-b3e1-4d3f-b8a6-596ed52da98f",
   "metadata": {},
   "source": [
    "import lhapdf\n",
    "\n",
    "# generate interpolation grid: increase this number!\n",
    "grid = generate_grid(1000000)\n",
    "\n",
    "# perform convolution with PDFs: this performs the x1 and x2 integrals of the partonic cross sections with the PDFs as given by our master formula\n",
    "pdf = lhapdf.mkPDF(\"NNPDF31_nnlo_as_0118_luxqed\", 0)\n",
    "bins = grid.convolve_with_one(2212, pdf.xfxQ2, pdf.alphasQ2)\n",
    "\n",
    "# matplotlib's 'step' function requires the last value to be repeated\n",
    "bins = np.append(bins, bins[-1])\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.set_xlabel(r\"$|y_{\\ell\\ell}|$\")\n",
    "ax.set_ylabel(r\"$\\mathrm{d} \\sigma / \\mathrm{d} |y_{\\ell\\ell}|$ [pb]\")\n",
    "ax.step(np.arange(0.0, 2.4, 0.1), bins, where='post')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ce14177a-e01c-4b00-86fb-ff47aeb4d76a",
   "metadata": {},
   "source": [
    "## Concluding remarks\n",
    "\n",
    "This was only a piece of a full calculation. For a full calculation we'd also need to calculate:\n",
    "\n",
    "- quark-anti-quark initial-states, $q\\bar{q} \\to \\ell\\bar{\\ell}$, which are large and therefore important\n",
    "- for reliable theory predictions, we should also calculate NLO and NNLO QCD predictions\n",
    "- if we scan the invariant mass range of Drell-Yan, we should also calculate NLO electroweak corrections $\\mathcal{O} (\\alpha^3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a00830-e1a5-4c5f-9c93-983c04090e6f",
   "metadata": {},
   "source": [
    "# Next-to-leading-order (NLO) calculations recipe modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e252bf-e94d-478a-bb3e-4de1d4000e0d",
   "metadata": {},
   "source": [
    "Our considerations so far are dealing with a leading-order calculation - what changes if we go to higher perturbative orders? In order to investigate this let's consider a simpler example than Drell-Yan: the computation of DIS structure functions. Although this calculation is conceptionally much simpler it turns out that higher-order corrections bring a whole new level of complication at any level of our algorithm. We will thus refrain from giving all details, but instead try to convey the most relevant ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193dd1f6-883c-4030-b474-3379d22e6c9b",
   "metadata": {},
   "source": "## 1. Draw all Feynman diagrams"
  },
  {
   "cell_type": "markdown",
   "id": "71dd3531-284e-40f4-ac0e-09ec3dba5c97",
   "metadata": {},
   "source": [
    "Starting at next-to-leading order (NLO) we need to consider genuinely new contributions: virtual corrections, real emissions, including new partonic channels. Let's discuss them in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d304b78-4bf6-4ea4-ae91-a80b24e94c8e",
   "metadata": {},
   "source": [
    "### Virtual corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618b595-e6b7-4d4e-8c4a-30e215e6e180",
   "metadata": {},
   "source": [
    "- add propagators inside diagrams to form loops\n",
    "- Example on blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409597c-21ed-4277-a976-d795522d3b81",
   "metadata": {},
   "source": [
    "### Real corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d3a39-6242-422f-a22f-96b79bcccb3a",
   "metadata": {},
   "source": [
    "- gluons and other particle can be emitted off any any point in the diagram\n",
    "- Example on blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f955b6-69ae-4966-94a7-ad51da5bd451",
   "metadata": {},
   "source": [
    "### New partonic channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbabe4-13e3-49c9-8548-e98ac8958396",
   "metadata": {},
   "source": [
    "- you need to consider also the case of new initial state partons\n",
    "- Look at DIS for example (blackboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ed314-58ad-4114-96b7-33fcd7b2f4f9",
   "metadata": {},
   "source": [
    "### Diagram generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403e0fc-b3a1-430e-8c77-a189aec0dd46",
   "metadata": {},
   "source": [
    "- in general, when there are many diagrams, an automatic program for diagram generation is needed, for instance qgraf or FeynArts\n",
    "- actually \"drawing\" is not really needed as long as you have a way to generate them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bab272-27ec-4193-87d1-0d27473fc56f",
   "metadata": {},
   "source": "## 2. Compute all matrix elements"
  },
  {
   "cell_type": "markdown",
   "id": "57a6aebf-4569-4cef-b99c-43698bf80c4f",
   "metadata": {},
   "source": [
    "### Virtual corrections\n",
    "\n",
    "- the loop momentum appearing in loop diagrams is arbitrary and thus needs to be integrated over\n",
    "- this generates singularities, which require a regularization procedure\n",
    "- the triangle can be calulated by hand, more complicated examples usually require one to numerically evaluate them using so-called loop-libraries, for instance https://qcdloop.web.cern.ch\n",
    "\n",
    "### Real corrections\n",
    "\n",
    "- like the virtual corrections, the real corrections also contain singularities\n",
    "- these singularities arise when integrating over the phase space of the additional particle\n",
    "\n",
    "### Cancellation of singularities between real and virtual contributions\n",
    "\n",
    "- singularities in the virtual contribution cancel against singularities in the real correction (if you choose your observables properly). The integrals themselves are different though\n",
    "- Widely used method to subtract real and virtual: Catani-Seymour Dipole subtraction \n",
    "\n",
    "### General bookkeeping issues\n",
    "\n",
    "- in general the number of diagrams grows factorially with the number of external particles and thus requires good bookkeeping for the corresponding mathematical terms\n",
    "- automation needed everywhere: we can't evaluate more than two-handful of diagrams by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c10c1-6e10-4315-acbc-997e0a2d8eda",
   "metadata": {},
   "source": "## 3. Determine phase space decomposition"
  },
  {
   "cell_type": "markdown",
   "id": "8c8f2630-a2a9-49a4-be61-7c535a4d7be4",
   "metadata": {},
   "source": "- real corrections have one more FS particle than LO and virtual and so requires different phase-space integration"
  },
  {
   "cell_type": "markdown",
   "id": "475bd098-6a9f-4776-baff-921a4c97c284",
   "metadata": {},
   "source": "## 4. Compute phase space integrals"
  },
  {
   "cell_type": "markdown",
   "id": "6a4848eb-5bb8-4fea-8587-27d0c135740d",
   "metadata": {},
   "source": [
    "- in DIS phase-space integrals are usually solvable using classical integration methods (good control over errors)\n",
    "- for processes with many final-state particles the phase-space is $3n - 4$, for instance $n=6$ requires one to perform a 14- (+2 from PDF convolutions) dimensional integral, which requires Monte Carlo integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf51e8-5e54-4c87-b605-fd2c04c0a5a2",
   "metadata": {},
   "source": "## 5. Join phase space and matrix elements"
  },
  {
   "cell_type": "markdown",
   "id": "eec70aac-c3dd-4edd-b651-70959fd83568",
   "metadata": {},
   "source": [
    "- matrix elements, especially virtual corrections, are significantly more expensive than LO to evaluate\n",
    "- usually requires a computing cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca1e74-1bf6-4c5f-b118-8ace70b62014",
   "metadata": {},
   "source": [
    "# Next up: DIS structure functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8451a-3b3c-422e-815a-7cd600556ecf",
   "metadata": {},
   "source": [
    "Open `dis.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00070a6-7d42-4e49-873c-ab0ae7dd2498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
