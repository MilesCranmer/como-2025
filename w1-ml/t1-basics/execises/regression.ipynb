{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c00a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7990a",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c6fc2",
   "metadata": {},
   "source": [
    "The idea of this tutorial is to make you familiar with the construction of a simple neural network model to fit a function and, in particular, to the `tensorflow` library. The main steps are the following:\n",
    "\n",
    "1. Choose a function to fit and generate fake data according to it simulating also experimental errors.\n",
    "2. Visualize the data.\n",
    "3. Construct a NN model to fit the function and train it to the data.\n",
    "4. Evaluate the predictions of your model.\n",
    "5. (Bonus task) Adopt a replica approach: generate different fake data replica and fit a different model to each replica. Then use the envelope of the predictions to get an uncertainty band. \n",
    "\n",
    "Some of the notebook's cells have been left with partial code to guide you but you are free to solve the problem in the way you prefer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ef5c5",
   "metadata": {},
   "source": [
    "## Function of nature that we would like to discover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aad40d",
   "metadata": {},
   "source": [
    "Here we define the function we are going to discover along with a gaussian smearing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_truth(x):\n",
    "    return (3*x**3 - x**2 + 5*x - 3)\n",
    "\n",
    "def func_to_fit(x, scale):\n",
    "    return np.random.normal(loc = f_truth(x), scale = scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94da6022",
   "metadata": {},
   "source": [
    "Here we generate noisy data based on the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b034028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.random.rand(200)\n",
    "y_vals = func_to_fit(x_vals, scale=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73049061",
   "metadata": {},
   "source": [
    "Before we start, visualize the data we are going to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...plotting here...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d7e24",
   "metadata": {},
   "source": [
    "## Let's now build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462735f8",
   "metadata": {},
   "source": [
    "It is time to build the model. Let's define a function for that. Use the `tensorflow` `Dense` layers and add them to the model with the function `model.add()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f77722",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.Input(shape=(1,)) #input layer\n",
    "model = keras.Sequential([input_layer])\n",
    "#...rest of the model here...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d4dd0",
   "metadata": {},
   "source": [
    "Now define an appropriate *loss* and an appropriate *optimizer*. Finally compile your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebabde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(#...#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12e7b3",
   "metadata": {},
   "source": [
    "Look at the summary of your model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54552e44",
   "metadata": {},
   "source": [
    "## Let's train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a50c800",
   "metadata": {},
   "source": [
    "It is finally time to train the model to the fake data. To do that we just need to call the function `model.fit()`. Look at the `tensorflow` documentation to understand which inputs it needs.\n",
    "\n",
    "Also make sure to separate the data into a training and a validation set, such that we can do [early stopping](https://en.wikipedia.org/wiki/Early_stopping) to prevent overtraining. For this we can use the [EarlyStopping](https://keras.io/api/callbacks/early_stopping/) callback provided by Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(#...#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f0dd0",
   "metadata": {},
   "source": [
    "### Let's look at the training/valdation losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b59db",
   "metadata": {},
   "source": [
    "We can have a look to the loss values as a function of the epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c738df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(model_history.history)\n",
    "hist['epoch'] = model_history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb767941",
   "metadata": {},
   "source": [
    "We can also plot both the validation and training losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...plotting here...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d4188c",
   "metadata": {},
   "source": [
    "### Now let's look to predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007af32d",
   "metadata": {},
   "source": [
    "Let's now try to reconstruct the original function asking the model to predict the function over a linear grid in x. To do that you need to use the function `model.predict()`. Then plot your predictions and the original function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(0.0, 1.0, 50) # input grid for the prediction\n",
    "#...predict here...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae99ff",
   "metadata": {},
   "source": [
    "Plot the training and validation data, together with our prediction and real function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#... do the plotting here...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6825e",
   "metadata": {},
   "source": [
    "# (bonus exercise) adopt a replica approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee57a83",
   "metadata": {},
   "source": [
    "When we set `scale=1.0` above, this added a level of noise to model the uncertainty present in the data. It is also possible to propagate this uncertainty to our fits. \n",
    "\n",
    "One way to do this, is through the \"replica approach\" in which we do another sampling on top of our noisy data, where this sampling follow the uncertainty in the data (i.e. `scale=1.0`). If we do this $N_\\mathrm{replica} \\rightarrow \\infty$ times end up with a Monte Carlo distribution of datasets, that encode the uncertainty in the data. We can then simply fit $N_\\mathrm{replica}$ different models to those $N_\\mathrm{replica}$ dataset, to obtain a corresponding Monte Carlo distribution in the space of the fit function. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_como",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
